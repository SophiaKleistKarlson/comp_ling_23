{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06e7f427-1675-4fe4-9936-0f916d990ebd",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Getting ready\n",
    "In the first three chunks, I install packages and import modules. I also load the raw data and pick out the parts I need analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7226c2b-1e7d-492c-8158-3d8a9a9efbb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# install the needed packages\n",
    "%pip install spacy\n",
    "%pip install gensim\n",
    "%pip install pyLDAvis\n",
    "%matplotlib inline\n",
    "\n",
    "# after executing this chunk, I restart the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a74000c-9c1c-4a49-ab13-2b55e8bd3b04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#after restarting the kernel, I import the needed modules\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import gensim\n",
    "import numpy as np\n",
    "import spacy\n",
    "import pandas as pd \n",
    "\n",
    "!python3 -m spacy download da_core_news_sm\n",
    "nlp = spacy.load(\"da_core_news_sm\") #danish spacy \n",
    "\n",
    "import pyLDAvis.gensim\n",
    "import os, re, operator, warnings\n",
    "warnings.filterwarnings('ignore') # we don't need to pay attention to warnings right now\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from gensim.models import CoherenceModel, LdaModel, LsiModel, HdpModel\n",
    "from gensim.corpora import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99fcd20-36e7-4274-98f9-5fe2f5eae020",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys # check which version of python I'm using\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c829a4aa-e1ae-4de6-b079-af6997b08aa9",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Import and check out raw data\n",
    "\n",
    "After getting an overview of the raw data, I create a new dataframe from the raw data only including tweet ID, text of the tweet, timestamp and reference data (whether the tweet was original, retweeted or quoted).\n",
    "\n",
    "As only the 'text' column is called the same as in the original dataframe, the other three columns start out empty, but that's okay, because I just want a dataframe with columns the same length as in raw_data.\n",
    "\n",
    "Then I fill out the other three columns, \"ID\", \"time\" and \"reference\" with the data from the columns \"author_id\", \"created_at\" and \"referenced_tweets\" from raw_data.\n",
    "\n",
    "I also order the raw tweets after occurrence, to look at the most common (as en retweeted the most times) tweets, which will come in handy in the process of cleaning up the text. For example, the word \"flire\" (a nonsense word in Danish) kept coming up in the topic modeling, which I realized was an incorrect lemmatization of \"flirte\" (to flirt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc14f91f-80f2-4754-9377-8835a20a6553",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_json('../data/normstormerne.ndjson', lines=True) # load raw data\n",
    "\n",
    "raw_data # view data\n",
    "print(list(raw_data.keys())) # overview of the columns in the data\n",
    "\n",
    "df = pd.DataFrame(raw_data, columns=['ID', 'text', 'time', 'reference']) # create new dataframe with the columns I need\n",
    "\n",
    "# fill out empty columns\n",
    "df['ID'] = raw_data['author_id']\n",
    "df['time'] = raw_data['created_at']\n",
    "df['reference'] = raw_data['referenced_tweets']\n",
    "\n",
    "# check out the data\n",
    "#print(df[0:20]) # view the 20 first rows of the new dataset\n",
    "#print(df['text'][0:20]) # check out the tweet texts specifically\n",
    "\n",
    "common_raw_tweets = Counter(raw_data['text']).most_common() # get a look at the most common tweets in the dataset\n",
    "#print(common_raw_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4db3f0-6714-47d2-bfb1-41a65ac8bcd0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Plot the timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc59894b-d995-4fb0-9029-489b21d7291a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Density plot\n",
    "\n",
    "#print(df['time'].info) #look at the data\n",
    "#print((df['time'][0]))\n",
    "\n",
    "df_time = pd.DataFrame(df, columns=['ID', 'time', 'ordinal', 'tweets_pr_day'])\n",
    "df_time = df_time.iloc[::-1] # as the data shows the most recent tweets first, I flip the dataframe, so I can plot it in chronological order\n",
    "\n",
    "df_time['ordinal'] = [x.toordinal() for x in df_time.time] #create a column \"ordinal\" with values extracted from the ordinal timestamp column\n",
    "\n",
    "df_time.to_csv(\"df_time.csv\")\n",
    "\n",
    "#print(df_time[0:10])\n",
    "#print(type(df_time['ordinal'][0]))\n",
    "\n",
    "ax = df_time['ordinal'].plot(kind='kde') #kde = kernel density estimation\n",
    "\n",
    "x_ticks = ax.get_xticks() #I'm still not quite sure what the x_ticks do, and I couldn't find good information on it online\n",
    "ax.set_xticks(x_ticks)\n",
    "\n",
    "# to zoom in on the media storm, I put xmin to 738305 (the date 2022-05-30), just before the mediastorm really starts\n",
    "x_lim = (min(df_time['ordinal']), max(df_time['ordinal']))\n",
    "ax.set_xlim(x_lim)\n",
    "\n",
    "# to get the dates as labels for the x axis\n",
    "xlabels = [datetime.datetime.fromordinal(int(x)) \n",
    "               .strftime('%m-%d-%Y') for x in x_ticks]\n",
    "\n",
    "ax.set_xticklabels(xlabels) #set x axis labels\n",
    "plt.title(\"Density of tweets mentioning Normstormerne\", size = 15) #title\n",
    "\n",
    "# set the figure size and layout\n",
    "plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "plt.savefig('fig1.png') #save it for the paper\n",
    "plt.show() #show here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8119c765-556e-4a80-a2e4-f10380702772",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the days with most tweets\n",
    "count_tweet_days = Counter(df_time['ordinal']).most_common()\n",
    "\n",
    "#check out the data\n",
    "print(len(count_tweet_days))\n",
    "print(count_tweet_days[0:5])\n",
    "\n",
    "for t in range(len(df_time['tweets_pr_day'])):\n",
    "    for c in range(len(count_tweet_days)):\n",
    "        if df_time['ordinal'][t] == count_tweet_days[c][0]:\n",
    "            df_time['tweets_pr_day'][t] = count_tweet_days[c][1]\n",
    "\n",
    "# save this dataframe to make it easier to inspect\n",
    "df_time.to_csv(\"df_time.csv\")\n",
    "\n",
    "# make a shorter dataframe, that starts just before the media storm is about to begin (May 30, 2022)\n",
    "df_time_short = df_time[43:3526]\n",
    "df_time_shorter = df_time[43:3095] # I can also zoom in even more on the period with the most tweets, but this doesn't actually tell us anything new\n",
    "\n",
    "#print(df_time)\n",
    "#print(df_time_short)\n",
    "\n",
    "#plot the whole time series as well as the plot starting on May 30 2022, just before the media storm started (the last tweet before this date was February 11 2022)\n",
    "df_time.plot(x='time', y='tweets_pr_day', xlabel='Date', ylabel='Number of tweets', title=\"Number of tweets per day mentioning Normstormerne\")\n",
    "df_time_short.plot(x='time', y='tweets_pr_day', xlabel='Date', ylabel='Number of tweets', title=\"Number of tweets per day mentioning Normstormerne\")\n",
    "df_time_shorter.plot(x='time', y='tweets_pr_day', xlabel='Date', ylabel='Number of tweets', title=\"Number of tweets per day mentioning Normstormerne\")\n",
    "\n",
    "#you can see from plot 3 that twitter really exploded around August 2, where a representative from Normstormerne went on the TV program \"Deadline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd3176c-e815-41fa-ade4-3d60e2953374",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# look at some timeline numbers\n",
    "print(len(df_time_shorter)) # 3052 tweets are shown on the last plot\n",
    "print(738401-738347) # number of days with the most tweets (54) , from July 11-September 3, 2022\n",
    "print((3383-500)/3525) # 81,78 % of tweets were created during these 54 days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd8d5c0-eca4-47e4-b1db-ba064701332c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Clean up the references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc63fb7c-321b-4168-8ce7-2f6808bc4e36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# clean up the reference column\n",
    "\n",
    "for t in range(len(df['reference'])):\n",
    "    if type(df['reference'][t]) == list: # if the tweet is an original tweet, the cell is just blank in the dataframe, so first I have to distinguish between whether the index consists of a list (which replies, retweets and quotes do) or not\n",
    "        df['reference'][t] = list(df['reference'][t][0].values())[0]\n",
    "    else:\n",
    "        continue # if t is not a list (in the cases when the cell is empty because it's an original tweet), skip to the next iteration\n",
    "\n",
    "#print(type(raw_data['text']))\n",
    "count_references = Counter(df['reference']).most_common() # get a look at the most common tweets in the dataset\n",
    "print(count_references) #prints [('replied_to', 1845), ('retweeted', 1096), (nan, 460), ('quoted', 124)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2a7b27-572a-4c59-8ba4-5c8f12659b6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Look at top tweeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6664dae-b2a6-470e-9ee0-6b370c7f2b85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "common_tweeters = Counter(df['ID']).most_common() # get a look at the most common tweets in the dataset\n",
    "\n",
    "# I wanted to look (very exploratory) on how many tweets different tweeters made, so I created a new column for this\n",
    "df['tweets_pr_ID'] = df['ID']\n",
    "\n",
    "for t in range(len(df['tweets_pr_ID'])):\n",
    "    for c in range(len(common_tweeters)):\n",
    "        if df['tweets_pr_ID'][t] == common_tweeters[c][0]:\n",
    "            df['tweets_pr_ID'][t] = common_tweeters[c][1]\n",
    "            \n",
    "print(f'''number of tweeters: {len(common_tweeters)}''')\n",
    "print(f'''number of tweets per tweeters: {3525/len(common_tweeters)}''')\n",
    "common_tweeters[0:10] # how many tweets did the top 10 tweeters tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebb8313-9509-49c8-a3b2-3e6146286c38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# i also add a column to the dataframe displaying tweets per day (makes it easy to explore when the media storm was on it's highest)\n",
    "\n",
    "df['tweets_pr_day'] = df['ID'] # first I just add another column with the same length as the others (copy the ID column just for simplicity)\n",
    "\n",
    "for t in range(len(df['ID'])):\n",
    "    for i in range(len(df_time['time'])):\n",
    "        if df['time'][t] == df_time['time'][i]:\n",
    "            df['tweets_pr_day'][t] = df_time['tweets_pr_day'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4acc8f2-f129-42f7-9acb-bd2938685b98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This chunk gives us the mean and standard deviation of tweets per ID\n",
    "tweet_pr_ID_list = []\n",
    "\n",
    "for i in range(len(common_tweeters)):\n",
    "    tweet_pr_ID_list.append(common_tweeters[i][1])\n",
    "\n",
    "#print(tweet_pr_ID_list[0:20])\n",
    "print(np.std(tweet_pr_ID_list)) #get the standard deviation\n",
    "print(np.average(tweet_pr_ID_list)) #get the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4999dca-d34c-40c5-8e82-0cbe4b513b4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This chunk gives us the mean and standard deviation of tweets per day\n",
    "\n",
    "count_tweet_days = Counter(df_time['ordinal']).most_common() #most busy tweet days\n",
    "\n",
    "tweet_pr_day_list = [] # empty list\n",
    "\n",
    "for i in range(len(count_tweet_days)):\n",
    "    tweet_pr_day_list.append(count_tweet_days[i][1])\n",
    "\n",
    "# subtract the smallest ordinal timestamp in the dataset (equivalent to the first day of data collection) from highest timestamp, and subtract the number of days with tweets (the length of the count_tweet_days list)\n",
    "days_without_tweets = ((max(df_time['ordinal'])-min(df_time['ordinal']))-(len(count_tweet_days))) # there were 933 in the period of collection with no tweets\n",
    "\n",
    "zero_list = [0]*(days_without_tweets) # make 933 0's\n",
    "#print(zero_list)\n",
    "tweet_pr_day_list = tweet_pr_day_list + zero_list # add the 933 0's to the tweet_pr_day_list\n",
    "#print(tweet_pr_day_list[0:300])\n",
    "\n",
    "# now we can get the average n of tweets per day and the standard deviation\n",
    "# - of course we didn't have to do all this to get the average, but we do for the SD\n",
    "print(np.average(tweet_pr_day_list)) # Mean = 3.100263852242744. \n",
    "print(np.std(tweet_pr_day_list)) # SD = 19.28644809096694"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d276aab-2131-4131-ab81-7e6c1b709e83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# correlation between tweets per day and number of tweets per tweeter (I didn't mention this in the paper because of space limitations)\n",
    "rho = np.corrcoef(df['tweets_pr_day'], df['tweets_pr_ID'])\n",
    "print(rho) # r = -0.01290965, meaning no correlation at all (very close to zero)\n",
    "\n",
    "df.to_csv(\"almost_cleaned_tweets.csv\") # so I don't have to run all of this again every time I return to the code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20288870-cc71-4f9f-8a4e-ccea96a2461e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-05T16:59:09.026573Z",
     "iopub.status.busy": "2023-07-05T16:59:09.025779Z",
     "iopub.status.idle": "2023-07-05T16:59:09.396054Z",
     "shell.execute_reply": "2023-07-05T16:59:09.394988Z",
     "shell.execute_reply.started": "2023-07-05T16:59:09.026485Z"
    },
    "tags": []
   },
   "source": [
    "#### Cleaning up the text data\n",
    "\n",
    "The next chunk cleans up the text column of the dataframe. The for loop below loops through the text column and does the following things:\n",
    "- Removes mentions - by substituting any string that starts with \"@\" with nothing (\"\"). NB: This procedure leaves extra spaces that I remove at the end of the loop)\n",
    "- Removes links that start with https - again, substititutes a string that starts with \"https\" with \"\"\n",
    "- Removes \"RT\" from the beginning of retweeted tweets - same procedure as the two steps above\n",
    "- Removes punctuation. NB: this also gets rid of emojis - which could of course also be analysed if the goal was sentiment analysis\n",
    "- Makes everything lowercase\n",
    "- Streamlines words that have multiple spellings in the dataset, e.g. \"lgbt+\" \"lgbt\" and \"lgbtq\" where the spelling variants don't usually reflect different intentions of the author (there just isn't a consensus on which acronym to use)\n",
    "- Corrects some obvious misspellings, such as \"indvander\" (changed to \"indvandrer\") and \"identitetespolitisk\" (changed to \"identitetspolitisk\")\n",
    "- Takes care of a few bigrams, such as the political party \"radikale venstre\", where \"radikal\" by itself might be misunderstood and \"venstre\" in itself could refer to the party, the direction or a political leaning to the left (where venstre is right wing and radikale venstre is central)\n",
    "- Collects words with very similar meanings such as \"folkeskolelærer\", \"skolelærer\" and \"lærer\" and collects \"københavn\" and its abbreviation \"kbh\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c343c6c4-cdbf-40a5-b335-7be9d9b4b81d",
   "metadata": {},
   "source": [
    "##### More indepth notes on the second round of normalization that didn't make it into the paper itself:\n",
    "\n",
    "During the second round of normalization, I chose to streamline some word types, i.e., rename different types into a single one. This was done for words with multiple spellings in the dataset, for types that I judged as synonyms for each-other, and in cases where conjugations of the same word were not caught by the lemmatizer. For example, all spelling variants of lgbt* were renamed lgbt, as versions such as “LGBT+” or “LGBTQ” usually reflect a lack of consensus on the acronym, rather than different intentions of the author. Similarly, the abbreviation kbh was changed to københavn. \n",
    "\n",
    "In some cases, I chose to combine nouns and verbs that in terms of content relay more or less the same information – such as indoktrinering* and indoktrinere*, that were renamed simply indoktrin. In the case of politik*, politisk*, politiser*, all were changed to politik – because although the different words carry slightly different meanings, it is more meaningful to the topic modeling to bundle up all references to politics in one.\n",
    "\n",
    "It was observed that the text had instances of both lærer*, skolelærer*, and folkeskolelærer*, all of which refer to (primary school) teachers. These three types were renamed simply lærer. Using the same principle, folkeskole* was changed to just skole. I also chose to rename all word types starting with undervis* to just undervis. This included the types undervise, underviser as well as undervisning and was done mostly because the types, although different word classes, refer to the general concept of teaching. Furthermore, because underviser can refer both to a person and a present verb, and undervisning can refer to teaching in general, but also a specific lesson, the nuances in meaning would have to be assessed with a part-of-speech tagging. I decided that this differentiating was not necessary for the current analysis, although one could definitely argue that it is bad practice to rename only specific types in a corpus but not follow a rigid set of principles for renaming similar types throughout the body of text. For example, I did not collect lære and lærer, even though the latter can both refer to a teacher but also present form of “to learn”. \n",
    "\n",
    "Another choice of bundling up words with similar meaning was to collect all mentions of NS’s teaching material into the word materiale. This included undervisningsmateriale, uvm (the abbreviation), *manual* (with asterisk both in front and back of the type as undervisningsmanual also occurred), and finally drejebog. \n",
    "\n",
    "A few obvious misspellings were corrected, such as indvander which was changed to indvandrer and identitetespolitisk, changed to identitetspolitisk. A few compound nouns were also corrected. For example, køns- og identitetspolitik was changed to kønspolitik og identitetspolitik, and køns identitet was renamed kønsidentitet. Two bigrams were collected to one string, namely pink washing, renamed pinkwashing, and radikale venstre which was renamed rv. In the case of radikale venstre (a political party), I made sure that venstre had to be followed by a space, so as not to catch den radikale venstrefløj or the like. \n",
    "\n",
    "Finally, the type kønss occurred 33 times in the data, and by further inspection, it turned out to originate from a tweet retweeted 32 times that referred to juridisk kønss. My interpretation was that kønss most likely was a shortening of kønsskifte, as juridisk kønsskifte, i.e., legal gender reassignment, is a fairly common bigram and currently a hot topic within the gender discourse in Denmark (at least anecdotally from my own experience). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6463d3b6-bb9c-4647-88f1-19234211eb9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# final text normalization \n",
    "df = pd.read_csv('almost_cleaned_tweets.csv') #import data, so I don't have to run everything above again\n",
    "\n",
    "for t in range(len(df['text'])):\n",
    "    \n",
    "    # remove strings that we are not interested in\n",
    "    df['text'][t] = re.sub(\"@\\S*\", \"\", df['text'][t]) # remove mentions\n",
    "    df['text'][t] = re.sub(\"https\\S*\", \"\", df['text'][t]) # remove links\n",
    "    df['text'][t] = re.sub(\"RT\", \"\", df['text'][t]) # remove \"RT\"\n",
    "    df['text'][t] = re.sub(\"[0-9]\", \"\", df['text'][t]) # remove numbers\n",
    "\n",
    "    # after removing \"RT\" which has to be upper case, we make everything else lower case\n",
    "    df['text'][t] = df['text'][t].lower() # Make everything lowercase\n",
    "\n",
    "    # take care of a few compound nouns\n",
    "    df['text'][t] = re.sub(\"køns- og identitetspolitik\\S*\", \"kønspolitik og identitetspolitik\", df['text'][t]) # change versions \"køns-\" where the intention is a compound noun\n",
    "    df['text'][t] = re.sub(\"køns- og seksualpolitik\\S*\", \"kønspolitik og seksualpolitik\", df['text'][t]) # change versions \"køns-\" where the intention is a compound noun\n",
    "    df['text'][t] = re.sub(\"køns- og normkritik\\S*\", \"kønskritik og normkritik\", df['text'][t]) # change versions \"køns-\" where the intention is a compound noun\n",
    "    \n",
    "     # after taking care of the compound nouns and hashtags, I remove punctuation\n",
    "    df['text'][t] = re.sub(r\"[^\\w\\s]\", \"\", df['text'][t]) # remove punctuation\n",
    "    \n",
    "    # further text cleanup: \n",
    "    # group together words that have multiple spellings/versions with the same meaning\n",
    "    df['text'][t] = re.sub(\"normst\\S*\", \"normstorm\", df['text'][t]) # make all versions of normst* into just normstorm (I have noticed \"normst\", \"normsto\", \"normstorm\", \"normstorme\", \"normstormer\" and \"normstormerne\" in the dataset alongside \n",
    "    df['text'][t] = re.sub(\"lgb\\S*\", \"lgbt\", df['text'][t]) # make all versions of lgbt* (including lgb) into just lgbt (someone might intentially write lgb to exclude trans people, but it seems more meaningful to group it with the other versions of the abbreviation)\n",
    "    df['text'][t] = re.sub(\"indoktrin\\S*\", \"indoktrin\", df['text'][t]) # make all versions of indoktrin* into just indoktrin (OBS: there is one version of \"indoktrineringsmateriale\" which will become indoktrin and thus not counted as \"materiale\"\n",
    "    df['text'][t] = re.sub(\"ideolog\\S*\", \"ideologi\", df['text'][t]) # collect different observed versions of ideologi (also seen as ideologer and ideologisk)\n",
    "    df['text'][t] = re.sub(\"politisk\\S*|politik\\S*|politiser\\S*\", \"politik\", df['text'][t]) # collect politisk, politik, politiker, politisere and other similar words that refer to politics\n",
    "\n",
    "    # sort out some of the most common words with \"køn\" in it\n",
    "    df['text'][t] = re.sub(\"kønss$\", \"kønsskifte\", df['text'][t]) # change kønss to kønsskifte - one tweet has been retweetet 32 times that mentions \"jurisk kønss\", which very most likely refers to \"juridsk kønsskifte\"\n",
    "    df['text'][t] = re.sub(\"køns$\", \"køn\", df['text'][t]) # change køns to køn (the lemmatizer doesn't do this)\n",
    "    df['text'][t] = re.sub(\"kønsidenti\\S*|køns identi\\S*\", \"kønsidentitet\", df['text'][t]) # collect different observed spellings of kønsidentitet\n",
    "    df['text'][t] = re.sub(\"kønsideolog\\S*\", \"kønsideologi\", df['text'][t]) # collect different versions of kønsideologi (also seen as kønsideologer and kønsideologisk)\n",
    "    \n",
    "    # collect \"kbhs\", \"københavns\" and \"københavnsk\" to \"kbh\"\n",
    "    df['text'][t] = re.sub(\"københavn\\S*\", \"kbh\", df['text'][t]) \n",
    "    df['text'][t] = re.sub(\"kbh\\S*\", \"kbh\", df['text'][t]) # make all versions of normstorm* into just normstorm\n",
    "\n",
    "    # collect all the words that refer to Normstormerne's teaching material under the word \"materiale\"\n",
    "    df['text'][t] = re.sub(\"uvm\\S*\", \"materiale\", df['text'][t]) # change the abbreviation \"uvm\" (\"undervisningsmateriale\") to \"materiale\"\n",
    "    df['text'][t] = re.sub(\"\\S*material\\S*\", \"materiale\", df['text'][t]) # change any compound noun that includes \"materiale\" to \"materiale\" (e.g. \"instruktionsmateriale\")\n",
    "    df['text'][t] = re.sub(\"\\S*manual\\S*\", \"materiale\", df['text'][t]) # \"manual\" has also been used to refer to the material\n",
    "    df['text'][t] = re.sub(\"drejebog\\S*\", \"materiale\", df['text'][t]) # \"drejebog\" has also been used to refer to the material\n",
    "    \n",
    "    # collect the words for teaching and teacher\n",
    "    df['text'][t] = re.sub(\"undervis\\S*\", \"undervis\", df['text'][t]) # collect versions of \"undervis*\" into \"undervis\", including undervisning and underviser - although if \"underviser\" refers to a teacher and not the present \"teaches\" then it might be misleading to collect them, as I don't collect \"lærer\" and \"lære\" for example\n",
    "    df['text'][t] = re.sub(\"^skolelærer|folkeskolelærer\", \"lærer\", df['text'][t]) # collect \"skolelærer\" and \"folkeskolelærer\" to just \"lærer\"\n",
    "    df['text'][t] = re.sub(\"folkeskole\", \"skole\", df['text'][t]) # change \"folkeskole\" to just \"skole\"\n",
    "\n",
    "    # collect a few bigrams\n",
    "    df['text'][t] = re.sub(\"radikale venstre \", \"rv \", df['text'][t]) # remove the space from the bigram \"radikale venstre\" (the bigram has to end with a space, so we dont get e.g. \"radikale venstrefløj\" (the radical leftwing)\n",
    "    df['text'][t] = re.sub(\"pink washing\", \"pinkwashing\", df['text'][t]) # collect \"pink washing\" to \"pinkwashing\" (the latter occurs a few times already)\n",
    "\n",
    "    # correct a few misspellings\n",
    "    df['text'][t] = re.sub(\"indvander\", \"indvandrer\", df['text'][t]) # change \"indvander\" til \"indvandrer\"\n",
    "    df['text'][t] = re.sub(\"identitetespolitisk\", \"identitetspolitisk\", df['text'][t]) # \"identitetspolitisk\" is miss-spelled \"identitetespolitisk\" at some point\n",
    "    df['text'][t] = re.sub(\"radikalevenster\", \"rv\", df['text'][t]) # correct this typo of \"radikale venstre\"\n",
    "    \n",
    "    # last touch\n",
    "    df['text'][t] = \" \".join(df['text'][t].split()) # Remove extra spaces (in the original tweets and left over from removing unwanted strings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a767c3aa-2615-47df-a7bf-724e61432317",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"cleaned_tweets.csv\") # so I don't have to run all of this again every time I return to the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e43d64-0e49-42a4-a95d-cf0861c3a19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_tweets.csv') # import data again when I proceed to the next steps of analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a05862-d22b-459a-8d1c-a96bc98169a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Stop words, bag of words and corpus\n",
    "\n",
    "I create a stopword list from a Danish one that I found here: https://gist.github.com/berteltorp/0cf8a0c7afea7f25ed754f24cfc2467b#file-stopord-txt\n",
    "\n",
    "After a few iterations of topic modeling and inspecting results, I add a bunch of stop words that I have noticed weren't in the original stop word list. \n",
    "\n",
    "I also add normstorm (which includes all versions of normstorm*) and it's abbreviation \"ns\" to the stop list because I know it will be present in all the tweets and will therefore skew the search - but it might be helpful for other kinds of analysi thus I only add it to the stop word list, instead of removing it from the dataset entirely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e34e70d-555e-4991-9ae7-695b95d3f4af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read the stop word list\n",
    "with open('stopord.txt') as f:\n",
    "    lines = f.read() \n",
    "\n",
    "stopwords = lines.split() # split the words at line break\n",
    "\n",
    "for w in range(len(stopwords)):\n",
    "    stopwords[w] = re.sub(r\"[^\\w\\s]\", \"\", stopwords[w]) # remove punctuation\n",
    "\n",
    "#print(stopwords)\n",
    "#print(type(stopwords))\n",
    "\n",
    "# add more stop words\n",
    "# there are a few tweets that use two, three or four line breaks, so I add these as stop words\n",
    "more_stopwords = ['\\n\\n'] +['\\n\\n\\n'] + ['\\n\\n\\n\\n'] + ['tja'] + ['haha'] + ['hahaha'] + ['inkl'] + ['mfl'] + ['dvs'] + ['arh'] + ['aah'] + ['mm'] + ['nb'] + ['jvf'] + ['ka'] + ['cirka'] + ['ogeller'] + ['ml'] + ['kl'] + ['mht'] + ['ps'] + ['f'] + ['h'] + ['s'] + ['p'] + ['r'] + ['evt'] + ['næh'] + ['no'] + ['nix'] + ['an'] + ['ik'] + ['pr'] + ['org'] + ['oh'] + ['åh'] + ['mf'] + ['ve'] + ['pa'] + ['ang'] + ['vh'] + ['iflg'] + ['bliv'] + ['ska'] + ['nan']\n",
    "\n",
    "# I also add \"normstorm\" and it's abbreviation \"ns\" to it's own small stop word list that I can choose to add to the big one or not - for this analysis, I'm adding them\n",
    "ns_stopwords = ['normstorm'] + ['ns'] \n",
    "\n",
    "# combine the stop word lists\n",
    "stopwords = stopwords + ns_stopwords + more_stopwords\n",
    "\n",
    "# check that all the words in the stop word list are actually stop words according to Spacy's is_stop function\n",
    "for stopword in stopwords:\n",
    "    #print(stopword)\n",
    "    lexeme = nlp.vocab[stopword]\n",
    "    #print(lexeme)\n",
    "    lexeme.is_stop = True # I'm not sure if this actually works though, because it accept all words I try to feed it\n",
    "\n",
    "# get a look at the stop words in alphabetical order\n",
    "#print(sorted(more_stopwords))\n",
    "#print(sorted(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2c5cd5-6d6d-4f1c-9aae-bab828b99372",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_str = '' #make an empty string\n",
    "\n",
    "for i in range(len(df['text'])):\n",
    "    text_str = text_str + str(df['text'][i]) + '''\\n''' #add every tweet in the text column to the text string, devided by a line shift\n",
    "    \n",
    "doc = nlp(text_str) # tokenize the text with spacy, thus making it into a \"Doc\" object\n",
    "\n",
    "#print(df['text'][0]) #see what the first word is in the first tweet, so I can check that the tokenization worked - the first word is \"er\"\n",
    "assert doc[0].text == \"er\" # the first token is \"er\", so everything seems in order \n",
    "\n",
    "#check out the doc\n",
    "#print(doc)\n",
    "#type(doc)\n",
    "\n",
    "# make three empty lists: one for all of the tweets, one for each individual tweet and one bag of words where order doesn't matter\n",
    "tweet, all_tweets, bag_of_words = [], [], [] \n",
    "\n",
    "# go through every tweet and sort out the stop words, before adding the tweet to the text\n",
    "for w in doc:\n",
    "    if w.text != '\\n' and not w.is_stop and not w.is_punct and not w.like_num: # if w is not a stop word or a number (including written out numbers)\n",
    "        tweet.append(w.lemma_) # then add the lematized version of the word to the tweet list\n",
    "        bag_of_words.append(w.lemma_) # also append the word to the bag of words\n",
    "    if w.text == '\\n': # if w is a new line then we're onto our next tweet\n",
    "        all_tweets.append(tweet) # and in that case, add the tweet to the all_tweets list\n",
    "        tweet = [] # and clean the tweet list, so we can begin filling it with the next tweet\n",
    "\n",
    "dictionary = Dictionary(all_tweets) # make the all_tweets list into a dictionary\n",
    "corpus = [dictionary.doc2bow(text) for text in all_tweets] #make the dictionary into a corpus that we can do topic modeling on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c99fb8-9f23-4c8d-b4d5-3ed549091db5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check out the new objects I just made\n",
    "print(dictionary)\n",
    "print(corpus[0:20])\n",
    "print(bag_of_words[0:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ce8e28-35d6-4397-b7a4-6f701047cf20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check out the most common words in the bag of words (the corpus is also in \"bag of words\" style, but vectorised, so this is an easy way to get the most common words\n",
    "common_words = Counter(bag_of_words).most_common() # get a look at the most common words used in the tweets\n",
    "\n",
    "common_words[0:30]\n",
    "#print(len(common_words)) # there are 6867 types in the bag of words, after preprocessing\n",
    "\n",
    "#print(common_words[0:50])#[6850:6866] # I look both at some of the most common and most uncommon words\n",
    "#print(sorted(common_words)) # I also look the words sorted alphabetically and can see that the lemmatizer has given some words capital letters, maybe words that it doesn't understand because they are English or abbreviations so it assumes that they are names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344749f9-0d5b-4193-9faf-a4e71ad40059",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Topic modeling\n",
    "\n",
    "We're now ready to topic model! I use two different models, LDA and HDP. Because HDP decides itself how many topics the text has (and it always decides on 20 every time I run it), I choose to run LDA with 2-20 topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdc4e0e-a766-4a9d-9fce-82269c8351d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prepare a function that plots coherence values of topic models\n",
    "def evaluate_bar_graph(coherences, indices):\n",
    "    \"\"\"\n",
    "    Function to plot bar graph.\n",
    "    Coherences: list of coherence values\n",
    "    Indices: Indices to be used to mark bars.\n",
    "    \"\"\"\n",
    "    assert len(coherences) == len(indices) # check that the length of coherences equals the length of the indices\n",
    "    n = len(coherences) # get the length of each list of coherence values\n",
    "    x = np.arange(n) # on the x-axis we want the coherence values, arranged to be evenly spaced\n",
    "    plt.bar(x, coherences, width=0.2, tick_label=indices, align='center') # plot the coherence measure as bars, with \"indices\" as tick labels\n",
    "    plt.xlabel('Topic models')\n",
    "    plt.ylabel('Coherence value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a3b8df-dec0-44a7-86ed-0c7f1ac18f85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hierarchical Dirichlet Process (HDP) model\n",
    "hdpmodel = HdpModel(corpus=corpus, id2word=dictionary) # run the model\n",
    "\n",
    "# get the probability scores of each model (????)\n",
    "hdptopics = [[word for word, prob in topic] for topicid, topic in hdpmodel.show_topics(formatted=False)]\n",
    "\n",
    "# get coherence value\n",
    "hdp_coherence = CoherenceModel(topics=hdptopics[:10], texts=all_tweets, dictionary=dictionary, window_size=10).get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3812ea-f890-40bc-95a3-e28fd251c0d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Latent Dirichlet Allocation (LDA) model - try out models with 2-20 topics\n",
    "# this could definitely have been a loop...\n",
    "ldamodel2 = LdaModel(corpus=corpus, num_topics=2, id2word=dictionary)\n",
    "ldamodel3 = LdaModel(corpus=corpus, num_topics=3, id2word=dictionary)\n",
    "ldamodel4 = LdaModel(corpus=corpus, num_topics=4, id2word=dictionary)\n",
    "ldamodel5 = LdaModel(corpus=corpus, num_topics=5, id2word=dictionary)\n",
    "ldamodel6 = LdaModel(corpus=corpus, num_topics=6, id2word=dictionary)\n",
    "ldamodel7 = LdaModel(corpus=corpus, num_topics=7, id2word=dictionary)\n",
    "ldamodel8 = LdaModel(corpus=corpus, num_topics=8, id2word=dictionary)\n",
    "ldamodel9 = LdaModel(corpus=corpus, num_topics=9, id2word=dictionary)\n",
    "ldamodel10 = LdaModel(corpus=corpus, num_topics=10, id2word=dictionary)\n",
    "ldamodel11 = LdaModel(corpus=corpus, num_topics=11, id2word=dictionary)\n",
    "ldamodel12 = LdaModel(corpus=corpus, num_topics=12, id2word=dictionary)\n",
    "ldamodel13 = LdaModel(corpus=corpus, num_topics=13, id2word=dictionary)\n",
    "ldamodel14 = LdaModel(corpus=corpus, num_topics=14, id2word=dictionary)\n",
    "ldamodel15 = LdaModel(corpus=corpus, num_topics=15, id2word=dictionary)\n",
    "ldamodel16 = LdaModel(corpus=corpus, num_topics=16, id2word=dictionary)\n",
    "ldamodel17 = LdaModel(corpus=corpus, num_topics=17, id2word=dictionary)\n",
    "ldamodel18 = LdaModel(corpus=corpus, num_topics=18, id2word=dictionary)\n",
    "ldamodel19 = LdaModel(corpus=corpus, num_topics=19, id2word=dictionary)\n",
    "ldamodel20 = LdaModel(corpus=corpus, num_topics=20, id2word=dictionary)\n",
    "\n",
    "# get the probability scores of each model (????)\n",
    "# again, this could definitely have been a loop...\n",
    "ldatopics2 = [[word for word, prob in topic] for topicid, topic in ldamodel2.show_topics(formatted=False)]\n",
    "ldatopics3 = [[word for word, prob in topic] for topicid, topic in ldamodel3.show_topics(formatted=False)]\n",
    "ldatopics4 = [[word for word, prob in topic] for topicid, topic in ldamodel4.show_topics(formatted=False)]\n",
    "ldatopics5 = [[word for word, prob in topic] for topicid, topic in ldamodel5.show_topics(formatted=False)]\n",
    "ldatopics6 = [[word for word, prob in topic] for topicid, topic in ldamodel6.show_topics(formatted=False)]\n",
    "ldatopics7 = [[word for word, prob in topic] for topicid, topic in ldamodel7.show_topics(formatted=False)]\n",
    "ldatopics8 = [[word for word, prob in topic] for topicid, topic in ldamodel8.show_topics(formatted=False)]\n",
    "ldatopics9 = [[word for word, prob in topic] for topicid, topic in ldamodel9.show_topics(formatted=False)]\n",
    "ldatopics10 = [[word for word, prob in topic] for topicid, topic in ldamodel10.show_topics(formatted=False)]\n",
    "ldatopics11 = [[word for word, prob in topic] for topicid, topic in ldamodel11.show_topics(formatted=False)]\n",
    "ldatopics12 = [[word for word, prob in topic] for topicid, topic in ldamodel12.show_topics(formatted=False)]\n",
    "ldatopics13 = [[word for word, prob in topic] for topicid, topic in ldamodel13.show_topics(formatted=False)]\n",
    "ldatopics14 = [[word for word, prob in topic] for topicid, topic in ldamodel14.show_topics(formatted=False)]\n",
    "ldatopics15 = [[word for word, prob in topic] for topicid, topic in ldamodel15.show_topics(formatted=False)]\n",
    "ldatopics16 = [[word for word, prob in topic] for topicid, topic in ldamodel16.show_topics(formatted=False)]\n",
    "ldatopics17 = [[word for word, prob in topic] for topicid, topic in ldamodel17.show_topics(formatted=False)]\n",
    "ldatopics18 = [[word for word, prob in topic] for topicid, topic in ldamodel18.show_topics(formatted=False)]\n",
    "ldatopics19 = [[word for word, prob in topic] for topicid, topic in ldamodel19.show_topics(formatted=False)]\n",
    "ldatopics20 = [[word for word, prob in topic] for topicid, topic in ldamodel20.show_topics(formatted=False)]\n",
    "\n",
    "# get the coherence measure of each model \n",
    "lda_coherence2 = CoherenceModel(topics=ldatopics2[:10], texts=all_tweets, dictionary=dictionary, window_size=10).get_coherence()# added the [:10] because it wasn't there before - not quite sure what difference it does\n",
    "lda_coherence3 = CoherenceModel(topics=ldatopics3[:10], texts=all_tweets, dictionary=dictionary, window_size=10).get_coherence()\n",
    "lda_coherence4 = CoherenceModel(topics=ldatopics4[:10], texts=all_tweets, dictionary=dictionary, window_size=10).get_coherence()# added the [:10] because it wasn't there before - not quite sure what difference it does\n",
    "lda_coherence5 = CoherenceModel(topics=ldatopics5[:10], texts=all_tweets, dictionary=dictionary, window_size=10).get_coherence()# added the [:10] because it wasn't there before - not quite sure what difference it does\n",
    "lda_coherence6 = CoherenceModel(topics=ldatopics6[:10], texts=all_tweets, dictionary=dictionary, window_size=10).get_coherence()# added the [:10] because it wasn't there before - not quite sure what difference it does\n",
    "lda_coherence7 = CoherenceModel(topics=ldatopics7[:10], texts=all_tweets, dictionary=dictionary, window_size=10).get_coherence()# added the [:10] because it wasn't there before - not quite sure what difference it does\n",
    "lda_coherence8 = CoherenceModel(topics=ldatopics8[:10], texts=all_tweets, dictionary=dictionary, window_size=10).get_coherence()# added the [:10] because it wasn't there before - not quite sure what difference it does\n",
    "lda_coherence9 = CoherenceModel(topics=ldatopics9[:10], texts=all_tweets, dictionary=dictionary, window_size=10).get_coherence()# added the [:10] because it wasn't there before - not quite sure what difference it does\n",
    "lda_coherence10 = CoherenceModel(topics=ldatopics10[:10], texts=all_tweets, dictionary=dictionary, window_size=10).get_coherence()# added the [:10] because it wasn't there before - not quite sure what difference it does\n",
    "lda_coherence11 = CoherenceModel(topics=ldatopics11[:10], texts=all_tweets, dictionary=dictionary, window_size=10).get_coherence()# added the [:10] because it wasn't there before - not quite sure what difference it does\n",
    "lda_coherence12 = CoherenceModel(topics=ldatopics12[:10], texts=all_tweets, dictionary=dictionary, window_size=10).get_coherence()# added the [:10] because it wasn't there before - not quite sure what difference it does\n",
    "lda_coherence13 = CoherenceModel(topics=ldatopics13[:10], texts=all_tweets, dictionary=dictionary, window_size=10).get_coherence()# added the [:10] because it wasn't there before - not quite sure what difference it does\n",
    "lda_coherence14 = CoherenceModel(topics=ldatopics14[:10], texts=all_tweets, dictionary=dictionary, window_size=10).get_coherence()# added the [:10] because it wasn't there before - not quite sure what difference it does\n",
    "lda_coherence15 = CoherenceModel(topics=ldatopics15[:10], texts=all_tweets, dictionary=dictionary, window_size=10).get_coherence()# added the [:10] because it wasn't there before - not quite sure what difference it does\n",
    "lda_coherence16 = CoherenceModel(topics=ldatopics16[:10], texts=all_tweets, dictionary=dictionary, window_size=10).get_coherence()# added the [:10] because it wasn't there before - not quite sure what difference it does\n",
    "lda_coherence17 = CoherenceModel(topics=ldatopics17[:10], texts=all_tweets, dictionary=dictionary, window_size=10).get_coherence()# added the [:10] because it wasn't there before - not quite sure what difference it does\n",
    "lda_coherence18 = CoherenceModel(topics=ldatopics18[:10], texts=all_tweets, dictionary=dictionary, window_size=10).get_coherence()# added the [:10] because it wasn't there before - not quite sure what difference it does\n",
    "lda_coherence19 = CoherenceModel(topics=ldatopics19[:10], texts=all_tweets, dictionary=dictionary, window_size=10).get_coherence()# added the [:10] because it wasn't there before - not quite sure what difference it does\n",
    "lda_coherence20 = CoherenceModel(topics=ldatopics20[:10], texts=all_tweets, dictionary=dictionary, window_size=10).get_coherence()# added the [:10] because it wasn't there before - not quite sure what difference it does\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08d228a-99cd-4caa-8e85-4a9fd83de097",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ldamodel20 = LdaModel(corpus=corpus, num_topics=20, id2word=dictionary)\n",
    "ldatopics20 = [[word for word, prob in topic] for topicid, topic in ldamodel20.show_topics(formatted=False)]\n",
    "lda_coherence20 = CoherenceModel(topics=ldatopics20[:10], texts=all_tweets, dictionary=dictionary, window_size=10).get_coherence()# added the [:10] because it wasn't there before - not quite sure what difference it does\n",
    "\n",
    "evaluate_bar_graph([lda_coherence2, lda_coherence3, lda_coherence4, lda_coherence5, lda_coherence6, lda_coherence7, lda_coherence8, lda_coherence9, lda_coherence10, lda_coherence11, lda_coherence12, lda_coherence13, lda_coherence14, lda_coherence15, lda_coherence16, lda_coherence17, lda_coherence18, lda_coherence19, lda_coherence20],\n",
    "                   ['LDA2', 'LDA3', 'LDA4', 'LDA5', 'LDA6', 'LDA7', 'LDA8', 'LDA9','LDA10', 'LDA11', 'LDA12', 'LDA13', 'LDA14', 'LDA15', 'LDA16', 'LDA17', 'LDA18', 'LDA19', 'LDA20'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e719b03-97b4-453e-bd9a-465f03e582d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print and compare some of the best LDA model and the HDP model performances\n",
    "print(hdp_coherence)\n",
    "print(lda_coherence16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854465bf-9afd-4d8a-b431-8db28ae0a0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results: show the topics of the best performing models:\n",
    "ldamodel16.show_topics(num_topics=16) # Latent Dirichlet Allocation (LDA) model with 16 topics\n",
    "hdpmodel.show_topics() # Hierarchical Dirichlet Process (HDP) model with 20 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e982a972-6443-43e0-b201-5551b359f7db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with LDA I can also make a fancy visualization that comes in handy when trying out different numbers of topics (even though LDA seem to be the least coherent model)\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.gensim.prepare(ldamodel16, corpus, dictionary) \n",
    "\n",
    "# by putting the relevance metric to 0.0, I can zoom in on words that are relatively unique to a given topic, even if they might not occur that many times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9664538-4819-4f65-b895-013dbb5ab1e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# some extra things I could have looked at\n",
    "\n",
    "# collocations\n",
    "\n",
    "# bag of words - 20 most common words - maybe word cloud\n",
    "\n",
    "# make negative bi-grams for loaded words, e.g. \"identitetspolitik\" or \"højreradikal\", to see if some people are saying that is ISN'T those things\n",
    "\n",
    "# compare different LDA models with varied amounts of topics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
